
filePath = "/home/maurice/temp/fileupload"
extractPath = "/home/maurice/temp"

script {
  settings {
    namespace = "actio.datapipes.task.Term.Functions"
    version = "v2"
  }
  tasks {
    unzip_tar_gz {
      type = extract
      dataSource {
        type = zip
        query {
          read {
            path = ${filePath}
            extractPath = ${extractPath}
          }
        }
      }
    }
    read_json_file {
      type = extract
      size = 1
      dataSource {
        type = "file"
        behavior = "json"
        directory = ${extractPath}
        query {
          read {
            filenameTemplate = "${name}"
          }
        }
      }
    }
    write_stage_DB {
      type = stage_load
      dataSource = ${datalake_datasource}
      dataSource {
        query {
          initialise = "CREATE TABLE IF NOT EXISTS datalake.t_${array(0).parameters.view}(runid uuid, createddate timestamp without time zone DEFAULT now(), configname character varying(100), pipename character varying(100), parameters jsonb, data jsonb)"
          create = "insert into datalake.t_${array(0).parameters.view}(runid,configname,pipename,parameters,data) values ('${array(0).run.id}','${array(0).run.configName}','${array(0).run.pipeName}','${sq(array(0).parameters.toJson())}','${sq(array(0).array.toJson())}')"
        }
      }
    }
    print_display {
      type = dump
      format = "json"
    }
  }
  pipelines {
    p_fileready {
      pipe = "unzip_tar_gz | read_json_file | write_stage_DB"
    }
  }
  startup {
    exec = "p_fileready"
  }
}
